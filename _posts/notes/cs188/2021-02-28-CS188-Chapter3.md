---
layout: post
title: CS188 Chapter 3 Searching Methods
Author: Mark
tags: Notes CS188
---

### 3.0 How do we Evaluate a Search Algorithm

We can evaluate a searching method in several aspects, as shown below:

>* **Consistency**, given a State Space with Goal State in it, the algorithm MUST can find an action sequence that leads to the goal state
>* **Optimality**, Given a State Space that has Goal State in it, the searching algorithm Must can find the Best Action Sequence that can lead to the Goal State
>* **Time Complexity**
>* **Space Complexity**

### 3.1 BFD Breadth First Search

Breadth First Search can be used to search in the state space to find a sequence of actions that will lead to the Goal State.

The BFD algorithm **First expand the shallowest node in the state space**.

Breadth First Search is a very useful searching method, since it can fulfill two important requirements to a Searching Algorithm:

* Complement
* Optimal

When all actions has the same cost, the first Goal State BFS has found is the State that needs **Least Actions** to reach, so the cost is optimal among all the Searching Methods.

In BFS: the Fringe of BFS, the Fringe is a **Stack** that applies the FIFO policy.

```python
def breadthFirstSearch(problem):
    """Search the shallowest nodes in the search tree first."""
    "*** YOUR CODE HERE ***"
    from util import Queue

    ExploredNodes = set()
    FringeNodes = Queue()

    InitialState = problem.getStartState()

    FringeNodes.push((InitialState, []))

    while not FringeNodes.isEmpty():
        NowNodeData = FringeNodes.pop()
        NowState = NowNodeData[0]
        NowPath = NowNodeData[1]
        
        if problem.isGoalState(NowState): return NowPath

        # If the Node has been explored
        if NowState in ExploredNodes: continue

        ExploredNodes.add(NowState)
        Successors = problem.getSuccessors(NowState)

        for Successor in Successors:
            action = Successor[1]
            SuccessorState = Successor[0]

            ActionSequence = NowPath[:]
            ActionSequence.append(action)
            FringeNodes.push((SuccessorState, ActionSequence))
```

### 3.2 DFS Depth First Search

Depth First Search can be used to search in the state space to find a sequence of actions that will lead to the Goal State as well.

The DFS algorithm will **First expand the Deepest node in the State space**

Depth First Search Algorithm need **Much Less Space** comparing to BFS, but it is not such a great searching algorithm since it does not fulfill the requirement of **Optimal**. In other words, the DFS will not return the optimal solution first.

In the DFS, the Fringe is a **Queue**, which applies the FIFO policy.

```python 
def depthFirstSearch(problem):
    """
    Search the deepest nodes in the search tree first.

    Your search algorithm needs to return a list of actions that reaches the
    goal. Make sure to implement a graph search algorithm.

    To get started, you might want to try some of these simple commands to
    understand the search problem that is being passed in:
    """

    # print("Start:", problem.getStartState())
    # print("Is the start a goal?", problem.isGoalState(problem.getStartState()))
    # print("Start's successors:", problem.getSuccessors(problem.getStartState()))

    "*** YOUR CODE HERE ***"
    # problem.getStartState() -> StartState
    # problem.isGoalState(State) -> boolean (True or False)
    # problem.getSuccessors(State) -> [(str(StartState), str('#num' + 'StartState -> 
    # Successor's State')), ...]

    ExploredNodes = set()
    FringeNodes = list()

    InitialState = problem.getStartState()
    FringeNodes.append((InitialState, []))

    while len(FringeNodes) != 0:
        NewNodeData = FringeNodes.pop()
        NewState = NewNodeData[0]
        NewPath = NewNodeData[1]

        if problem.isGoalState(NewState): return NewPath

        # If the node has been explored
        if NewState in ExploredNodes: continue
        
        ExploredNodes.add(NewState)
        Successors = problem.getSuccessors(NewState)

        for Successor in Successors:
            action = Successor[1]
            SuccessorState = Successor[0]

            ActionSequence = NewPath[:]
            ActionSequence.append(action)
            FringeNodes.append((SuccessorState, ActionSequence))
```

### 3.3 UCS Uniform Cost Search

Both BFS and DFS has a problem that they does not care the **actual cost** of the action sequence it returns. Though the BFS DOES return the shrotest path to reach the goal state, it ignore the weight on each path. In fact, the shortest path usually is not the path with lowest cost.
The UCS, however, does concern about the cost of its action sequence. It do so by **First Expand the Lowest Cost Node among all nodes in the Fringe Sequence**

The strategy used by the UCS is quite like the strategy used in the MST (最小生成树)

In UCS, the Fringe is a **Priority Queue**, where the priority of items are the cost from initial state to the current state.

```python
def uniformCostSearch(problem):
    """Search the node of least total cost first."""
    "*** YOUR CODE HERE ***"
    
    import heapq
    
    ExploredNodes = set()
    Fringe = list()

    InitialState = problem.getStartState()
    heapq.heappush(Fringe, (0.0, 0, InitialState, []))

    SerialNum = 1
    while len(Fringe) != 0:
        NowNodeData = heapq.heappop(Fringe)
        NowNodeCost = NowNodeData[0]
        NowState = NowNodeData[2]
        NowPath = NowNodeData[3]

        if NowState in ExploredNodes: continue

        if problem.isGoalState(NowState):return NowPath
        
        ExploredNodes.add(NowState)
        Successors = problem.getSuccessors(NowState)

        for Successor in Successors:
            NextState = Successor[0]
            Action = Successor[1]
            NextCost = Successor[2]

            ActionSequence = NowPath[:]
            ActionSequence.append(Action)

            if not checkInList(NowState, Fringe):
                heapq.heappush(Fringe, (NowNodeCost + NextCost, SerialNum, NextState, ActionSequence))
            elif Fringe[checkInList(NowState, Fringe)][0] > (NowNodeCost + NextCost):
                Fringe[checkInList(NowState, Fringe)] = (NowNodeCost + NextCost, SerialNum, NextState, ActionSequence)
                heapq.heapify(Fringe)
            SerialNum += 1
```

In the UCS, we need to use the Priority Queue, there are two modulus in the Python that can perform the priority queue: `PriorityQueue` and `heapq`

### 3.4 A* Search

**A\* Search** is a kind of **Informed Search**, which gain some more knowledge about the question. Unlike the UCS method, which only focus on the cost from initial state to the current state, A* search also concern the approximate future cost of the action sequence.

**Admissive and Consistency** are two ways to evaluate whether a Heuristic Function is optimal or not. The A* search is optimal only if the Heuristic Function is both Admissive and Consistency.

Some common Heuristic Functions:

>Manhatten Distance:
>Manhatten Distance s the sum of verticle distance and the horizontal distance between goal state and current state.

```python
def ManhattenDistance(NowPosition, TargetPosition):
    Nowx, Nowy = NowPosition[0], NowPosition[1]
    Targetx, Targety = TargetPosition[0], TargetPosition[1]
    return (abs(Targetx - Nowx)+abs(Targety - Nowy))
```

>Euclid Distance:
>Euclid Distance is the linear distance between the current state and the goal state.

```python
import math
def EuclidDistance(NowPosition, TargetPosition):
    x, y = NowPosition
    dx, dy = TargetPosition
    return math.sqrt((dx - x)**2+(dy - y)**2)
```

The **Heuristic Function** is the function that will 'predict' the distance between given state and the goal state.
Notice that the distance is only be *predicted*, some poor Heuristic Function will not reduce the expanded nodes' number.

In A* Search, the Fringe is also a **Priority Queue**, the priority is the sum of cost from initial state to the current state and the value of Heuristic Function.

The code is shown below:

```python
def aStarSearch(problem, heuristic=nullHeuristic):
    """Search the node that has the lowest combined cost and heuristic first."""
    "*** YOUR CODE HERE ***"
    import heapq

    ExploredNodes = set()
    Fringe = list()

    InitialState = problem.getStartState()
    InitialHeuristic = heuristic(InitialState, problem)

    heapq.heappush(Fringe, (0.0+InitialHeuristic, 0.0, 0, InitialState, []))       # (c(S)+h(s), c(s), seqNum, State, Path)

    seqNum = 1

    while len(Fringe) != 0:
        NowNode = heapq.heappop(Fringe)
        EstimateCost = NowNode[0]       # c(s)+h(s)  -> float()
        ActualCost = NowNode[1]         # c(s)   -> float()
        NowState = NowNode[3]           # State
        ActionSequence = NowNode[4]     # Path -> list()

        if problem.isGoalState(NowState): return ActionSequence
        if NowState in ExploredNodes: continue
        ExploredNodes.add(NowState)

        Successors = problem.getSuccessors(NowState)
        for Successor in Successors:
            NextState = Successor[0]
            NextAction = Successor[1]
            NextCost = Successor[2]

            NextActionSequence = ActionSequence[:]
            NextActionSequence.append(NextAction)
            NextHeuristic = heuristic(NextState, problem)

            NextCost += ActualCost
            NextEstimate = NextCost + NextHeuristic

            check = AstarCheck(Fringe, NextState)
            if check and Fringe[check][0] > NextEstimate:
                Fringe[check] = (NextEstimate, NextCost, seqNum, NextState, NextActionSequence)
                heapq.heapify(Fringe)
            else:
                heapq.heappush(Fringe, (NextEstimate, NextCost, seqNum, NextState, NextActionSequence))
            seqNum += 1
```

Notice that a **A\* Search** will be optimistic when the Heuristic function is both admissive and consistent. It should be notice that there's a vast varity of functions can be selected as the Heuristic function (i.e. `return 0`), but only a good heuristic function is not trivial and can help up reduce the expanded nodes in the state space.

### 3.5 Greedy Search

Greedy search is one kind of application of greedy algorithm in the search problem.
Sometime it will take too much time for the algorithm to find a **optimal solution action sequence** in the huge state space. However, we don't need necessarily optimal solution in most situations. In this situation, we can use a *suboptimal* solution instead.

Greedy Search is a way to find the best solution in a local area and doing such an option repeatedly.

The code of Greedy Search does not has a fixed structure like that of UCS, BFS etc. So the code won't be shown below.

### *3.6 Prove the Optimality of A* Search

<div class="info">如果这里还是空着的说明 Mark 还在偷懒，不过你可以看 <em>Artificial Intelligence, A Modern Approach</em> Page 95, Section 3.5 - Optimality of A* 来自己研究这一部分</div>