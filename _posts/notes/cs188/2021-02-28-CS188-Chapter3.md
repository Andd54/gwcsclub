---
layout: post
title: CS188 Chapter 3 Searching Methods
Author: Mark
tags: Notes CS188
---



<div class="info">
    <h3>
        The Relationship between Searching and AI
    </h3>
    <p>
        As we have mentioned in chapter 1 and 2, an Intelligent Agent can maximize the utility in a given environment by control its behavior. Searching Algorithm is a very useful algorithm to find the <strong>sequence of actions</strong> that will maximize the utility.
    </p>
</div>

### Terminologies

| **Term**                  | **Explanation**                                              |
| ------------------------- | ------------------------------------------------------------ |
| State                     | One status of environment, which can be represented using a series of parameters |
| State Space               | All the states an environment can have. The state space can either be finite or infinite. |
| Action                    | The behavior of Agent. Usually Action can change the State (note: not *always*). |
| Fringe                    | The states in state space that is about to explore (expand) by the searching algorithm. |
| State Transition Function | The function that describe how state change between each other (how state transit). |
| Successor                 | The states that directly resulted from current state.<br />$\text{currState}\quad \underrightarrow{Action} \quad \text{Successors}$ |

### 3.0 How do We Evaluate a Search Algorithm

We can evaluate a searching method in several aspects, as shown below:

>* **Consistency**, given a State Space with Goal State in it, the algorithm MUST be able to find an action sequence that leads to the goal state.
>* **Optimality**, Given a State Space that has Goal State in it, the searching algorithm MUST be able to find the Best Action Sequence that can lead to the Goal State
>* **Time Complexity**, how many computation time it takes for the algorithm to find the Best Action Sequence to the Goal State
>* **Space Complexity**, how many memory it use for the algorithm to find the Best Action Sequence to the Goal State.

### 3.1 Breadth First Search (BFS)

> BFS is both Consistent and Optimal.

In the BFS algorithm, **The shallowest state in state space is expanded first**.

Due to this feature, when there are multiple goal states in the state space, the BFS can always find the shallowest goal state. Therefore, when all the actions have same cost, the BFS can always find the action sequence to goal state that have least cost.

The fringe of BFS is a **Stack** where FIFO policy applies.



**Code Example**

```python
def breadthFirstSearch(initialState, getSuccessor, getValidActions):
    """
    :param initialState: The Initial State of problem (sometimes the 'current state')
    :param getSuccessor: The State Transition Function that return the successors given the current state and action
    :param getValidActions: A function taht takes current state and return a list of valid actions under current state
    """
    fringe = stack()
    exploredStates = set()
    
    # Add the Initial State into the Fringe before Searching Actually Start.
    fringe.push(initialState)
    while len(fringe) > 0:
		currState = fringe.pop()
        if currState in exploredStates: continue
        else: exploredState.add(currState)
            
        # Do Something Here
        
        for action in getValidActions(currState):
            # Add Successor States into the fringe
            successor = getSuccessor(currState, action)
            if successor not in exploredStates: fringe.push(successor)
```

<center>Pros and Cons of BFS Algorithm</center>

| Pros                                                         | Cons                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| **The Optimality of Searching Result** - the nearest goal state will always return first | **High Space Complexity** - The BFS algorithm requires much memory to maintain the fringe. Suppose each state leads to $3$ successors, when searching on a tree with height $10$, the fringe will have a size of $3^{10}\approx 60000$. (Space Complexity $O(m^n)$) |
| **Easy to implement** - no complex data structure required, the foundation of most searching algorithms | **High Time Complexity** - Suppose the goal state is at depth $n$, and on average each state has $m$ successors, the time complexity of BFS will be $O(m^{n+1})$ |

### 3.2 Depth First Search (DFS)

> DFS is only Consistent, not Optimal

The DFS algorithm will **First expand the Deepest node in the State space**

Depth First Search Algorithm need **Much Less Space** comparing to BFS, but it is not such a great searching algorithm since it does not fulfill the requirement of **Optimal**. In other words, the DFS will not return the optimal solution first.

In the DFS, the Fringe is a **Queue**, which applies the FIFO policy.

```python 
def depthFirstSearch(problem):
    """
    Search the deepest nodes in the search tree first.

    Your search algorithm needs to return a list of actions that reaches the
    goal. Make sure to implement a graph search algorithm.

    To get started, you might want to try some of these simple commands to
    understand the search problem that is being passed in:
    """

    # print("Start:", problem.getStartState())
    # print("Is the start a goal?", problem.isGoalState(problem.getStartState()))
    # print("Start's successors:", problem.getSuccessors(problem.getStartState()))

    "*** YOUR CODE HERE ***"
    # problem.getStartState() -> StartState
    # problem.isGoalState(State) -> boolean (True or False)
    # problem.getSuccessors(State) -> [(str(StartState), str('#num' + 'StartState -> 
    # Successor's State')), ...]

    ExploredNodes = set()
    FringeNodes = list()

    InitialState = problem.getStartState()
    FringeNodes.append((InitialState, []))

    while len(FringeNodes) != 0:
        NewNodeData = FringeNodes.pop()
        NewState = NewNodeData[0]
        NewPath = NewNodeData[1]

        if problem.isGoalState(NewState): return NewPath

        # If the node has been explored
        if NewState in ExploredNodes: continue
        
        ExploredNodes.add(NewState)
        Successors = problem.getSuccessors(NewState)

        for Successor in Successors:
            action = Successor[1]
            SuccessorState = Successor[0]

            ActionSequence = NewPath[:]
            ActionSequence.append(action)
            FringeNodes.append((SuccessorState, ActionSequence))
```

### 3.3 UCS Uniform Cost Search

Both BFS and DFS has a problem that they does not care the **actual cost** of the action sequence it returns. Though the BFS DOES return the shrotest path to reach the goal state, it ignore the weight on each path. In fact, the shortest path usually is not the path with lowest cost.
The UCS, however, does concern about the cost of its action sequence. It do so by **First Expand the Lowest Cost Node among all nodes in the Fringe Sequence**

The strategy used by the UCS is quite like the strategy used in the MST (最小生成树)

In UCS, the Fringe is a **Priority Queue**, where the priority of items are the cost from initial state to the current state.

```python
def uniformCostSearch(problem):
    """Search the node of least total cost first."""
    "*** YOUR CODE HERE ***"
    
    import heapq
    
    ExploredNodes = set()
    Fringe = list()

    InitialState = problem.getStartState()
    heapq.heappush(Fringe, (0.0, 0, InitialState, []))

    SerialNum = 1
    while len(Fringe) != 0:
        NowNodeData = heapq.heappop(Fringe)
        NowNodeCost = NowNodeData[0]
        NowState = NowNodeData[2]
        NowPath = NowNodeData[3]

        if NowState in ExploredNodes: continue

        if problem.isGoalState(NowState):return NowPath
        
        ExploredNodes.add(NowState)
        Successors = problem.getSuccessors(NowState)

        for Successor in Successors:
            NextState = Successor[0]
            Action = Successor[1]
            NextCost = Successor[2]

            ActionSequence = NowPath[:]
            ActionSequence.append(Action)

            if not checkInList(NowState, Fringe):
                heapq.heappush(Fringe, (NowNodeCost + NextCost, SerialNum, NextState, ActionSequence))
            elif Fringe[checkInList(NowState, Fringe)][0] > (NowNodeCost + NextCost):
                Fringe[checkInList(NowState, Fringe)] = (NowNodeCost + NextCost, SerialNum, NextState, ActionSequence)
                heapq.heapify(Fringe)
            SerialNum += 1
```

In the UCS, we need to use the Priority Queue, there are two modulus in the Python that can perform the priority queue: `PriorityQueue` and `heapq`

### 3.4 A\* Search

**A\* Search** is a kind of **Informed Search**, which gain some more knowledge about the question. Unlike the UCS method, which only focus on the cost from initial state to the current state, A\* search also concern the approximate future cost of the action sequence.

**Admissive and Consistency** are two ways to evaluate whether a Heuristic Function is good or not. The A\* search is optimal only if the Heuristic Function is both Admissive and Consistency.

Some common Heuristic Functions:

>**Manhattan Distance**
>Manhattan Distance s the sum of vertical distance and the horizontal distance between goal state and current state.

```python
def ManhattenDistance(NowPosition, TargetPosition):
    Nowx, Nowy = NowPosition[0], NowPosition[1]
    Targetx, Targety = TargetPosition[0], TargetPosition[1]
    return (abs(Targetx - Nowx)+abs(Targety - Nowy))
```

>**Euclid Distance**
>Euclid Distance is the linear distance between the current state and the goal state.

```python
import math
def EuclidDistance(NowPosition, TargetPosition):
    x, y = NowPosition
    dx, dy = TargetPosition
    return math.sqrt((dx - x)**2+(dy - y)**2)
```

The **Heuristic Function** is the function that will 'predict' the distance between given state and the goal state.
Notice that the distance is only be *predicted*, some poor Heuristic Function will not reduce the expanded nodes' number.

In A* Search, the Fringe is also a **Priority Queue**, the priority is the sum of cost from initial state to the current state and the value of Heuristic Function.

The code is shown below:

```python
def aStarSearch(problem, heuristic=nullHeuristic):
    """Search the node that has the lowest combined cost and heuristic first."""
    "*** YOUR CODE HERE ***"
    import heapq

    ExploredNodes = set()
    Fringe = list()

    InitialState = problem.getStartState()
    InitialHeuristic = heuristic(InitialState, problem)

    heapq.heappush(Fringe, (0.0+InitialHeuristic, 0.0, 0, InitialState, []))       # (c(S)+h(s), c(s), seqNum, State, Path)

    seqNum = 1

    while len(Fringe) != 0:
        NowNode = heapq.heappop(Fringe)
        EstimateCost = NowNode[0]       # c(s)+h(s)  -> float()
        ActualCost = NowNode[1]         # c(s)   -> float()
        NowState = NowNode[3]           # State
        ActionSequence = NowNode[4]     # Path -> list()

        if problem.isGoalState(NowState): return ActionSequence
        if NowState in ExploredNodes: continue
        ExploredNodes.add(NowState)

        Successors = problem.getSuccessors(NowState)
        for Successor in Successors:
            NextState = Successor[0]
            NextAction = Successor[1]
            NextCost = Successor[2]

            NextActionSequence = ActionSequence[:]
            NextActionSequence.append(NextAction)
            NextHeuristic = heuristic(NextState, problem)

            NextCost += ActualCost
            NextEstimate = NextCost + NextHeuristic

            check = AstarCheck(Fringe, NextState)
            if check and Fringe[check][0] > NextEstimate:
                Fringe[check] = (NextEstimate, NextCost, seqNum, NextState, NextActionSequence)
                heapq.heapify(Fringe)
            else:
                heapq.heappush(Fringe, (NextEstimate, NextCost, seqNum, NextState, NextActionSequence))
            seqNum += 1
```

Notice that a **A\* Search** will be optimistic when the Heuristic function is both admissive and consistent. It should be notice that there's a vast variety of functions can be selected as the Heuristic function (i.e. `return 0`), but only a good heuristic function is not trivial and can help up reduce the expanded nodes in the state space.

### 3.5 Greedy Search

Greedy search is one kind of application of greedy algorithm in the search problem.
Sometime it will take too much time for the algorithm to find a **optimal solution action sequence** in the huge state space. However, we don't need necessarily optimal solution in most situations. In this situation, we can use a *suboptimal* solution instead.

Greedy Search is a way to find the best solution in a local area and doing such an option repeatedly.

The code of Greedy Search does not has a fixed structure like that of UCS, BFS etc. So the code won't be shown below.

### \*3.6 Prove the Optimality of A\* Search

<div class="info">如果这里还是空着的说明 Mark 还在偷懒，不过你可以看 <em>Artificial Intelligence, A Modern Approach</em> Page 95, Section 3.5 - Optimality of A* 来自己研究这一部分</div> 