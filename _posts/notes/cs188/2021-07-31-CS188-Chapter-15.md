---
layout: post
title: CS188 Chapter 15 Probabilistic Reasoning over Time
Author: ["Mark Chen"]
tags: [Notes, CS188]
---
<div class="error">
    <p>We are still working on this page ...</p>
</div>
<div class="info">
<em>In which we try to interpret the present, understand the past, and perhaps predict the future, even when very little is crystal clear.</em>
</div>

**belief state** that represents which states of the world are currently possible. From belief state and a **transition model**, the agent can predict how the world might evolve in the next step.

![How Belief State Evolves](http://markdown-img-1304853431.cosgz.myqcloud.com/20210731142523.jpg)

From information from the **sensor model**, agents can update the belief state.

![Use Sensor update Belief State](http://markdown-img-1304853431.cosgz.myqcloud.com/20210731142629.jpg)

In *previous* section, belief state can only tell which state is *possible*, but can't say which state is *likely* or *unlikely*. In this section, we can **quantify the degree of belief in the belief state**.

## 15.1 Time and Uncertainty

In previous section, we have talked about the Bayesian Network. Bayesian network can perform probabilistic reasoning in static world. The value of random variable at each moment is independent with its previous value.

However, in many scenario, the previous state **DO** influence the current state. To utilize such information, we use a model called **markov chain**.

### 15.1.1 States and observations

We view the world as a series of snapshots (a.k.a **time slices** and time is not continuous)

$\mathbf{X}_t$ denote the set of state variables at time $t$

$\mathbf{E}_t$ denote the set of observable evidence variables at time $t$

$\mathbf{E}_t = e_t$ where $e_t$ is the observed value for evidence variable.

We will assume that the state sequence starts at $t=0$ and evidence starts arriving at $t=1$.